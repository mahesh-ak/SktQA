{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7970a3-0f02-46a7-af0f-a5424e2c7674",
   "metadata": {},
   "source": [
    "## Load Conllu data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "08b92200-146f-4777-871b-16caf068d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0229296-df00-4fa4-9a5e-b02e7c8f5055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 257/257 [00:00<00:00, 8611.16it/s]\n"
     ]
    }
   ],
   "source": [
    "dcs_pth = 'data/raw/dcs/'\n",
    "dirs = os.listdir(dcs_pth)\n",
    "conllu_pths = {}\n",
    "for d in tqdm(dirs):\n",
    "    d_pth = os.path.join(dcs_pth,d)\n",
    "    files = os.listdir(d_pth)\n",
    "    conllu_pths[d_pth] = [os.path.join(d_pth,f) for f in files if '.conllu' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58cc940f-2a94-4ffd-bf2a-7d4f78b86b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7f65c6-029d-4fa6-bd0c-49f030630081",
   "metadata": {},
   "source": [
    "### Create DCS corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae35c48c-efc9-4a0c-9d71-08ab8f9566c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir_pth = 'data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d06b18de-4620-49f1-a948-5c3eb6cbe75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 257/257 [02:07<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "for d_pth, f_pths in tqdm(conllu_pths.items()):\n",
    "    txt = []\n",
    "    for f_pth in f_pths:\n",
    "        sentences = parse(open(f_pth, 'r', encoding='utf-8').read())\n",
    "        for sent in sentences:\n",
    "            if len(sent) == 0: continue\n",
    "            txt.append(' '.join([token['lemma'] for token in sent if token['lemma'] != '_']))\n",
    "    with open(f\"{d_pth.replace('raw/dcs','processed')}.txt\", 'w') as fp:\n",
    "        fp.write('\\n'.join(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bad022-e7c7-49bb-90f8-25bd4762773e",
   "metadata": {},
   "source": [
    "## GRETIL Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9674c0b-5938-42b5-8cf1-15b83470abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "gretil_pth = 'data/raw/gretil_txt/'\n",
    "files = os.listdir(gretil_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52cca3c7-c557-49f6-a977-d1999f64d5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'namas tvad rudra manyu uta iṣu namas bāhu uta tvad namas'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(model=\"mahesh27/t5lemmatizer\")\n",
    "pipe(\"namaste rudra manyava utota iṣave namaḥ\\n bāhubhyām uta te namaḥ</s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "937e3517-314e-4425-8c20-5dea8a42293e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\-'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\-'\n",
      "/tmp/ipykernel_1766529/275952512.py:7: SyntaxWarning: invalid escape sequence '\\-'\n",
      "  txt = re.sub('[,.\";_=\\-@#\\[\\]\\\\^%\\(\\)X*+\\|/]|[0-9]', '', txt)\n",
      "  0%|                                       | 3/1214 [01:55<12:59:03, 38.60s/it]\n",
      "/tmp/ipykernel_1766529/275952512.py:7: SyntaxWarning: invalid escape sequence '\\-'\n",
      "  txt = re.sub('[,.\";_=\\-@#\\[\\]\\\\^%\\(\\)X*+\\|/]|[0-9]', '', txt)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m txt \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m</s>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,txt\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m lines \u001b[38;5;241m=\u001b[39m txt\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m out_lines \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m out_lines_txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m out_lines])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/raw/gretil_lemmas/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/transformers/pipelines/text2text_generation.py:167\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    139\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[1;32m    172\u001b[0m     ):\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/transformers/pipelines/base.py:1235\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1232\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1233\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1234\u001b[0m     )\n\u001b[0;32m-> 1235\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/transformers/pipelines/base.py:1161\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1160\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1161\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/transformers/pipelines/text2text_generation.py:191\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m     in_b, input_length \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_inputs(\n\u001b[1;32m    187\u001b[0m     input_length,\n\u001b[1;32m    188\u001b[0m     generate_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmin_length),\n\u001b[1;32m    189\u001b[0m     generate_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_length),\n\u001b[1;32m    190\u001b[0m )\n\u001b[0;32m--> 191\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m out_b \u001b[38;5;241m=\u001b[39m output_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/transformers/generation/utils.py:1914\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1906\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1907\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1908\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1909\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1910\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1911\u001b[0m     )\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1914\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1928\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1929\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1931\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/transformers/generation/utils.py:2651\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2648\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2651\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2652\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2654\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2655\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2659\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1767\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtie_word_embeddings:\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;66;03m# Rescale output before projecting on vocab\u001b[39;00m\n\u001b[1;32m   1764\u001b[0m     \u001b[38;5;66;03m# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m sequence_output \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dim\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m-> 1767\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1769\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_base/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "for f_name in tqdm(files):\n",
    "    f_pth = os.path.join(gretil_pth, f_name)\n",
    "    out_pth = os.path.join('data/processed/', f_name)\n",
    "    txt = open(f_pth, 'r').read()\n",
    "    txt = re.sub('[,.\";_=\\-@#\\[\\]\\\\^%\\(\\)X*+\\|/]|[0-9]', '', txt)\n",
    "    txt = re.sub('ṁ','ṃ',txt)\n",
    "    txt = re.sub('\\n','</s>\\n',txt+'\\n')\n",
    "    lines = txt.split('\\n')\n",
    "    out_lines = pipe(lines, batch_size= batch_size, max_new_tokens=256)\n",
    "    out_lines_txt = '\\n'.join([x['generated_text'] for x in out_lines])\n",
    "    with open(f\"data/raw/gretil_lemmas/{f_name}\",'w') as fp:\n",
    "        fp.write(out_lines_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75468022-27ba-49bf-a2c0-7c869e7e84b6",
   "metadata": {},
   "source": [
    "### Testing lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4b280bba-a301-41d8-a193-f0646409ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "9145ffc5-4427-43d4-a8f3-778825dfbe1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__n27</td>\n",
       "      <td>ayaṁ sa yo divas pari raghuyāmā pavitra ā | si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__n6</td>\n",
       "      <td>pra mā yuyujre prayujo janānāṁ vahāmi sma pūṣa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__n5</td>\n",
       "      <td>nū indra rāye varivas kṛdhī na ā te mano vavṛt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__n0</td>\n",
       "      <td>tvaṁ no asyā uṣaso vyuṣṭau tvaṁ sūra udite bod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__n27</td>\n",
       "      <td>yathā pūrvebhyaḥ śatasā amṛdhraḥ sahasrasāḥ pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>__label__n24</td>\n",
       "      <td>śatam ahaṁ tirindire sahasram parśāv ā dade | ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>__label__n5</td>\n",
       "      <td>ayuyutsann anavadyasya senām ayātayanta kṣitay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>__label__n8</td>\n",
       "      <td>aśvā ived aruṣāsaḥ sabandhavaḥ śūrā iva prayud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>__label__n5</td>\n",
       "      <td>ye te santi daśagvinaḥ śatino ye sahasriṇaḥ | ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>__label__n6</td>\n",
       "      <td>ā dhenavo dhunayantām aśiśvīḥ sabardughāḥ śaśa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1424 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                              verse\n",
       "0     __label__n27  ayaṁ sa yo divas pari raghuyāmā pavitra ā | si...\n",
       "1      __label__n6  pra mā yuyujre prayujo janānāṁ vahāmi sma pūṣa...\n",
       "2      __label__n5  nū indra rāye varivas kṛdhī na ā te mano vavṛt...\n",
       "3      __label__n0  tvaṁ no asyā uṣaso vyuṣṭau tvaṁ sūra udite bod...\n",
       "4     __label__n27  yathā pūrvebhyaḥ śatasā amṛdhraḥ sahasrasāḥ pa...\n",
       "...            ...                                                ...\n",
       "1419  __label__n24  śatam ahaṁ tirindire sahasram parśāv ā dade | ...\n",
       "1420   __label__n5  ayuyutsann anavadyasya senām ayātayanta kṣitay...\n",
       "1421   __label__n8  aśvā ived aruṣāsaḥ sabandhavaḥ śūrā iva prayud...\n",
       "1422   __label__n5  ye te santi daśagvinaḥ śatino ye sahasriṇaḥ | ...\n",
       "1423   __label__n6  ā dhenavo dhunayantām aśiśvīḥ sabardughāḥ śaśa...\n",
       "\n",
       "[1424 rows x 2 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_pth = \"test/sup_test.txt\"\n",
    "\n",
    "df = pd.read_csv(f_pth, sep='\\t', names=['label', 'verse'])\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f5f619be-3dc1-4afb-851e-17d8cfc80d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'idam tad yad div pari raghu yāman pavitra ā sindhu ūrmi vi kṣar'}]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(model=\"mahesh27/t5lemmatizer\")\n",
    "\n",
    "pipe(''.join(df['verse'][0].split('||')[0].split('|'))+'</s>', max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f1af2359-7cca-484a-9736-431c73aa446d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 1424/1424 [00:00<00:00, 187602.13it/s]\n"
     ]
    }
   ],
   "source": [
    "df['verse'] = df.progress_apply(lambda x: ''.join(x['verse'].split('||')[0].split('|'))+'</s>',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "4883f2ec-0482-4a55-83eb-bde24ae456f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "verses = df['verse'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "700c1514-1900-491a-bfd0-f52d461e8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "diatrics_corr = {'r'+'̣':'ṛ', 's'+'̣':'ṣ', 'r'+'̣'+'̄': 'ṝ', 't'+'̣':'ṭ', 'd'+'̣':'ḍ', \n",
    "                 'n'+'̣':'ṇ', 'l'+'̱':'ḻ', 'a'+'̄':'ā', 'i'+'̄':'ī', 'u'+'̄':'ū', 's'+'́':'ś',\n",
    "                 'n'+'̇': 'ṅ', 'n'+'̃' : 'ñ',\n",
    "                }\n",
    "\n",
    "def corr_diatrics(sent):\n",
    "    new_sent = ''\n",
    "    sent = list(sent)\n",
    "    i = 0\n",
    "    while i<len(sent):\n",
    "        if i+1 < len(sent):\n",
    "            c2 = sent[i] + sent[i+1]\n",
    "            if c2 in diatrics_corr:\n",
    "                new_sent += diatrics_corr[c2]\n",
    "                i += 2\n",
    "                continue\n",
    "        new_sent += sent[i]\n",
    "        i += 1\n",
    "    return new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "24f85f3f-6699-4ec0-820e-bf7193f9a093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 178/178 [00:45<00:00,  3.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from itertools import batched\n",
    "import math\n",
    "\n",
    "new_verses = []\n",
    "batch_size = 8\n",
    "for batch in tqdm(batched(verses, batch_size), total=math.ceil(len(verses)/batch_size)):\n",
    "    lemmas = pipe(list(batch), batch_size=batch_size, max_new_tokens=64)\n",
    "    new_verses += [corr_diatrics(l['generated_text']) for l in lemmas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "043e1fea-3b19-4459-9556-d9bc8a492321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__n27</td>\n",
       "      <td>div pari raghu yāman pavitra sindhu ūrmi vi kṣar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__n6</td>\n",
       "      <td>pra yuj prayuj jana vah sma pūṣan antareṇa adh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__n5</td>\n",
       "      <td>nu indra rai varivas manas vṛt magha gomat aśv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__n0</td>\n",
       "      <td>uṣas vyuṣṭi tvac sūra udi gopā janman nitya ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__n27</td>\n",
       "      <td>sā amṛdhra sā paryaya vāja indu pū suvita navy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>__label__n24</td>\n",
       "      <td>tirindira parśu dā rādhas yādvan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>__label__n5</td>\n",
       "      <td>ayuyutt anavadya senā yātay kṣiti navagva vṛṣā...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>__label__n8</td>\n",
       "      <td>aśva id aruṣa sabandhu śūra prayudh pra uta yu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>__label__n5</td>\n",
       "      <td>daśagvin śatin sahasrin aśva vṛṣan raghudru tūya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>__label__n6</td>\n",
       "      <td>dhenu dhunī aśiśu sabardugha śaśaya apradugdha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1424 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                              verse\n",
       "0     __label__n27   div pari raghu yāman pavitra sindhu ūrmi vi kṣar\n",
       "1      __label__n6  pra yuj prayuj jana vah sma pūṣan antareṇa adh...\n",
       "2      __label__n5  nu indra rai varivas manas vṛt magha gomat aśv...\n",
       "3      __label__n0  uṣas vyuṣṭi tvac sūra udi gopā janman nitya ta...\n",
       "4     __label__n27  sā amṛdhra sā paryaya vāja indu pū suvita navy...\n",
       "...            ...                                                ...\n",
       "1419  __label__n24                   tirindira parśu dā rādhas yādvan\n",
       "1420   __label__n5  ayuyutt anavadya senā yātay kṣiti navagva vṛṣā...\n",
       "1421   __label__n8  aśva id aruṣa sabandhu śūra prayudh pra uta yu...\n",
       "1422   __label__n5   daśagvin śatin sahasrin aśva vṛṣan raghudru tūya\n",
       "1423   __label__n6  dhenu dhunī aśiśu sabardugha śaśaya apradugdha...\n",
       "\n",
       "[1424 rows x 2 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['verse'] = pd.Series(new_verses)\n",
    "\n",
    "stop_words = open(\"stop_words.txt\",'r').read().split('\\n')\n",
    "def remove_stop(sent):\n",
    "    sent = sent.split()\n",
    "    res = []\n",
    "    for w in sent:\n",
    "        if w not in stop_words:\n",
    "            res.append(w)\n",
    "    return ' '.join(res)\n",
    "\n",
    "df['verse'] = df.apply(lambda x: remove_stop(x['verse']), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "958e3f9c-7123-45f3-95c0-66b30c8fb890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f_pth, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217564c0-858f-465b-9f41-527c94c4930c",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "79cdebb6-c16b-464e-8b2a-0fcaa2447b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('data/processed.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2a5bb725-fffb-4399-b8c9-d2f2744f3ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ea031497-cd91-423a-aa50-66b6bd0edc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7418939"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9a9cea9e-65f4-44a9-95d8-26972c918cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_df = pd.DataFrame({'words': words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "626afbda-db3d-46b3-8b98-21e55de6d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = w_df.groupby('words').size().reset_index(name='freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2edac3a8-dda8-465f-84e2-69cb2ebbf168",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = freq_df.sort_values(by=['freq'], ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "403f909b-506d-4e25-8539-8ddba82acdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tad',\n",
       " 'ca',\n",
       " 'iti',\n",
       " 'mad',\n",
       " 'eva',\n",
       " 'yad',\n",
       " 'na',\n",
       " 'tvad',\n",
       " 'idam',\n",
       " 'etad',\n",
       " 'bhū',\n",
       " 'kṛ',\n",
       " 'sarva',\n",
       " 'as',\n",
       " 'vac',\n",
       " 'tu',\n",
       " 'api',\n",
       " 'mahat',\n",
       " 'vai',\n",
       " 'deva',\n",
       " 'hi',\n",
       " 'tatas',\n",
       " 'tathā',\n",
       " 'vā',\n",
       " 'atha',\n",
       " 'rājan',\n",
       " 'agni',\n",
       " 'iva',\n",
       " 'gam',\n",
       " 'evam',\n",
       " 'dṛś',\n",
       " 'su',\n",
       " 'vid',\n",
       " 'loka',\n",
       " 'indra',\n",
       " 'tatra',\n",
       " 'yathā',\n",
       " 'ka',\n",
       " 'ātman',\n",
       " 'sa',\n",
       " 'dharma',\n",
       " 'eka',\n",
       " 'putra',\n",
       " 'artha',\n",
       " 'dā',\n",
       " 'punar',\n",
       " 'ādi',\n",
       " 'yat',\n",
       " 'brahman',\n",
       " 'anya',\n",
       " 'brū',\n",
       " 'han',\n",
       " 'śru',\n",
       " 'karman',\n",
       " 'enad',\n",
       " 'ha',\n",
       " 'a',\n",
       " 'para',\n",
       " 'sva',\n",
       " 'ratha',\n",
       " 'yajña',\n",
       " 'tri',\n",
       " 'jan',\n",
       " 'sthā',\n",
       " 'tva',\n",
       " 'rūpa',\n",
       " 'ah',\n",
       " 'pitṛ',\n",
       " 'tadā',\n",
       " 'bala',\n",
       " 'kāla',\n",
       " 'rasa',\n",
       " 'kāma',\n",
       " 'manas',\n",
       " 'kaścit',\n",
       " 'tasmāt',\n",
       " 'saha',\n",
       " 'iha',\n",
       " 'brāhmaṇa',\n",
       " 'ā',\n",
       " 'yaj',\n",
       " 'hu',\n",
       " 'puruṣa',\n",
       " 'atra',\n",
       " 'prāṇa',\n",
       " 'yuj',\n",
       " 'paśu',\n",
       " 'ap',\n",
       " 'grah',\n",
       " 'soma',\n",
       " 'yadi',\n",
       " 'vāc',\n",
       " 'go',\n",
       " 'śata',\n",
       " 'ṛṣi',\n",
       " 'u',\n",
       " 'iṣ',\n",
       " 'dhā',\n",
       " 'prāp',\n",
       " 'adas',\n",
       " 'phala',\n",
       " 'vara',\n",
       " 'bahu',\n",
       " 'pā',\n",
       " 'pūrva',\n",
       " 'yā',\n",
       " 'mā',\n",
       " 'nara',\n",
       " 'sama',\n",
       " 'pāṇḍava',\n",
       " 'tapas',\n",
       " 'guṇa',\n",
       " 'viśva',\n",
       " 'śara',\n",
       " 'sahasra',\n",
       " 'satya',\n",
       " 'uttama',\n",
       " 'bhūta',\n",
       " 'yatra',\n",
       " 'man',\n",
       " 'prajā',\n",
       " 'pati',\n",
       " 'dvi',\n",
       " 'anna',\n",
       " 'namas',\n",
       " 'div',\n",
       " 'vīra',\n",
       " 'priya',\n",
       " 'tā',\n",
       " 'mukha',\n",
       " 'anta',\n",
       " 'pañcan',\n",
       " 'parama',\n",
       " 'jñā',\n",
       " 'pṛthivī',\n",
       " 'śrī',\n",
       " 'svāhā',\n",
       " 'guru',\n",
       " 'tejas',\n",
       " 'nāma',\n",
       " 'paś',\n",
       " 'ji',\n",
       " 'ahar',\n",
       " 'i',\n",
       " 'āgam',\n",
       " 'catur',\n",
       " 'kṛṣṇa',\n",
       " 'aśva',\n",
       " 'car',\n",
       " 'yoga',\n",
       " 'diś',\n",
       " 'adya',\n",
       " 'muni',\n",
       " 'bhagavant',\n",
       " 'pāpa',\n",
       " 'uttara',\n",
       " 'vīrya',\n",
       " 'jana',\n",
       " 'strī',\n",
       " 'vana',\n",
       " 'karṇa',\n",
       " 'madhya',\n",
       " 'katham',\n",
       " 'saptan',\n",
       " 'muc',\n",
       " 'bāhu',\n",
       " 'aṅga',\n",
       " 'mahātman',\n",
       " 'vad',\n",
       " 'sūrya',\n",
       " 'rāja',\n",
       " 'doṣa',\n",
       " 'vat',\n",
       " 'devatā',\n",
       " 'suta',\n",
       " 'bhārata',\n",
       " 'yudhiṣṭhira',\n",
       " 'divya',\n",
       " 'ati',\n",
       " 'smṛ',\n",
       " 'nṛpa',\n",
       " 'bhavat',\n",
       " 'daśan',\n",
       " 'sukha',\n",
       " 'vrata',\n",
       " 'yāvat',\n",
       " 'prajāpati',\n",
       " 'ja',\n",
       " 'āditya',\n",
       " 'vāyu',\n",
       " 'atas',\n",
       " 'devī',\n",
       " 'sattva',\n",
       " 'vipra',\n",
       " 'indriya',\n",
       " 'viṣṇu',\n",
       " 'gṛha',\n",
       " 'vāta',\n",
       " 'mātṛ',\n",
       " 'pārtha']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df['words'][:200].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "54cfb061-01ad-4de6-ae30-8af3d563b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = '\\n'.join(freq_df['words'][:200].tolist())\n",
    "with open(\"stop_words.txt\", 'w') as fp:\n",
    "    fp.write(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c4e0c87a-18f2-403b-a2eb-3fb9bc369d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('data/processed.txt','r').read().split('\\n')\n",
    "stop_words = open('stop_words.txt','r').read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ccac64ea-380a-4db3-b2b9-b3eea75d0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_stopw = []\n",
    "for line in text:\n",
    "    words = line.split()\n",
    "    new_line = []\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            new_line.append(w)\n",
    "    processed_stopw.append(' '.join(new_line))\n",
    "with open('processed_stop.txt','w') as fp:\n",
    "    fp.write('\\n'.join(processed_stopw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63709bc3-ab0e-4854-99da-de028fa0939a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
