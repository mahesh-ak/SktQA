{
	"(a) Named Entity Recognition": {
		"san": {
			"gpt-4o-mini": [
				0.6597476597476598,
				0.7222222222222222,
				0.5940012368583797,
				0.6527777777777778,
				0.26206896551724135,
				0.18679653679653682,
				0.43205813794049086,
				0.28865578865578867,
				0.28775510204081634,
				0.2855699855699856
			],
			"llama-v3p1-8b-instruct": [
				0.4107142857142857,
				0.07142857142857142,
				0.09523809523809525,
				0.09292929292929294,
				0.19444444444444445,
				0.0,
				0.06222222222222222,
				0.025974025974025976,
				0.043478260869565216,
				0.2043650793650794
			],
			"gpt-4o": [
				0.4938453159041394,
				0.47521367521367525,
				0.6451923076923077,
				0.875,
				0.29895104895104896,
				0.3276353276353276,
				0.483982683982684,
				0.5427350427350428,
				0.30380116959064324,
				0.5286437246963562
			],
			"llama-v3p1-405b-instruct": [
				0.6054987212276215,
				0.4258953168044078,
				0.5013205282112845,
				0.7696969696969697,
				0.358974358974359,
				0.3621399176954732,
				0.34498834498834496,
				0.3724937343358396,
				0.3443010752688172,
				0.24924379915305503
			]
		},
		"san<en>": {
			"gpt-4o-mini": [
				0.4462081128747795,
				0.4464285714285714,
				0.545534712201379,
				0.5757936507936509,
				0.257201646090535,
				0.2759259259259259,
				0.5002314814814816,
				0.30831649831649827,
				0.5230929989550679,
				0.2984873949579832
			],
			"llama-v3p1-8b-instruct": [
				0.4223901098901099,
				0.2452600875060768,
				0.3445887445887446,
				0.21666666666666665,
				0.17281105990783407,
				0.20166578061314902,
				0.19285714285714287,
				0.07623049219687875,
				0.12954545454545455,
				0.43146929824561403
			],
			"gpt-4o": [
				0.600473801560758,
				0.7436048799685163,
				0.7366946778711485,
				0.7372627372627373,
				0.5904761904761905,
				0.2615942028985507,
				0.45500459136822774,
				0.797008547008547,
				0.3964669738863288,
				0.4330132052821129
			],
			"llama-v3p1-405b-instruct": [
				0.5613095238095238,
				0.668548842461886,
				0.6352941176470589,
				0.5021645021645021,
				0.36054421768707484,
				0.3973063973063973,
				0.35858585858585856,
				0.5257936507936508,
				0.44980392156862736,
				0.703968253968254
			]
		},
		"lat": {
			"gpt-4o-mini": [
				0.49487295519031776,
				0.32040573864088334,
				0.3445670951307352,
				0.41323316896669643,
				0.3213515456506111,
				0.31933082084750436,
				0.38609745789696115,
				0.37343550446998725,
				0.3759300701975861,
				0.32700632700632704
			],
			"llama-v3p1-8b-instruct": [
				0.30990983982141934,
				0.14314789687924015,
				0.14587813620071685,
				0.17695006747638328,
				0.19268180876248844,
				0.15128826249724728,
				0.13423180592991912,
				0.11640809831878234,
				0.25352725705666884,
				0.15155546859714344
			],
			"gpt-4o": [
				0.6289956297819844,
				0.4528454211186836,
				0.40157022158456873,
				0.3832025527658652,
				0.3415946439440049,
				0.37583325737550516,
				0.4338624338624338,
				0.3780787202027402,
				0.3547782895255973,
				0.36392175725509057
			],
			"llama-v3p1-405b-instruct": [
				0.6582080022778221,
				0.5786887508626638,
				0.5515151515151516,
				0.520340179914648,
				0.42175538697616116,
				0.4553191489361703,
				0.4892448512585812,
				0.44977168949771684,
				0.40496898864038827,
				0.41693121693121693
			]
		},
		"lat<en>": {
			"gpt-4o-mini": [
				0.46662093358359774,
				0.4086341714660299,
				0.3732503607503608,
				0.3805717282979282,
				0.37984496124031003,
				0.4283706631532718,
				0.33838974947408684,
				0.44296119162429326,
				0.3522177015940773,
				0.3303567071683014
			],
			"llama-v3p1-8b-instruct": [
				0.29410815774452137,
				0.24903486337326694,
				0.19779693486590041,
				0.14276832502252168,
				0.13419129060480342,
				0.11779560308972074,
				0.13025641025641024,
				0.19162363740677,
				0.2070656092285508,
				0.1679634214595369
			],
			"gpt-4o": [
				0.7056296450188196,
				0.5782770562770562,
				0.463785046728972,
				0.507539625186684,
				0.5015873015873016,
				0.47320128277683454,
				0.4019830613509605,
				0.5466448266448266,
				0.4316046018197837,
				0.41031321619556915
			],
			"llama-v3p1-405b-instruct": [
				0.6687014706269357,
				0.6145519077196097,
				0.5164983164983165,
				0.5096961604235482,
				0.41822172584423045,
				0.46989463552140803,
				0.5446748591909881,
				0.410595314850634,
				0.41288713278183425,
				0.4027465667915106
			]
		},
		"grc": {
			"gpt-4o-mini": [
				0.4432812216214705,
				0.22626657239525286,
				0.17430009591546372,
				0.19260929589186512,
				0.26585446166607657,
				0.2595304121525888,
				0.2905411868109142,
				0.2920731246361172,
				0.3628775187954146,
				0.4483992379958689
			],
			"llama-v3p1-8b-instruct": [
				0.184149948864392,
				0.1770935636239496,
				0.12626220735287977,
				0.13276705544155998,
				0.19234183611055186,
				0.1834434250633353,
				0.23805102193080793,
				0.21677013566830095,
				0.2191364830367383,
				0.2491377964898691
			],
			"gpt-4o": [
				0.39829452626785034,
				0.27223601211793463,
				0.2357652363258407,
				0.26089710090138174,
				0.2880328679242077,
				0.23934987639577232,
				0.27641049589106204,
				0.28835756418712477,
				0.37850129730579685,
				0.416486205293626
			],
			"llama-v3p1-405b-instruct": [
				0.41495643197770854,
				0.24623560389661886,
				0.24465416900705236,
				0.27985819851341703,
				0.49890860528662306,
				0.31008617262911753,
				0.3190538863208354,
				0.33911650543827754,
				0.4264049236713365,
				0.5347552995138349
			]
		},
		"grc<en>": {
			"gpt-4o-mini": [
				0.3132455298608468,
				0.1630981583353328,
				0.16455372136927332,
				0.1820349824100393,
				0.18857148654599384,
				0.21583966097241125,
				0.19477248138072722,
				0.20252968589468084,
				0.2956791473205238,
				0.22761007108833198
			],
			"llama-v3p1-8b-instruct": [
				0.13007407407407406,
				0.14030631402988794,
				0.10159769727643453,
				0.09508361681518293,
				0.13306748036122143,
				0.10348976860397312,
				0.10212714418526374,
				0.10259808708037593,
				0.08562062857479852,
				0.11777101163045862
			],
			"gpt-4o": [
				0.3394766623972782,
				0.3014860478275113,
				0.3180316295961507,
				0.4065969441060495,
				0.5945132429322751,
				0.3264305977122838,
				0.3409919100984621,
				0.31829643156052656,
				0.46967189514298324,
				0.3895161784361411
			],
			"llama-v3p1-405b-instruct": [
				0.5945613592291359,
				0.2984449166364711,
				0.2896166186489582,
				0.3296049068176674,
				0.528505311886018,
				0.3291020065077287,
				0.34750020944874305,
				0.42258129787382476,
				0.4179241125009329,
				0.41485210721254157
			]
		}
	},
	"(b) Machine Translation to English": {
		"san": {
			"gpt-4o-mini": [
				0.06269203190084,
				0.07298964835309736,
				0.07232927350178348,
				0.07868631860260283,
				0.07500842319758556,
				0.09548955416518026,
				0.10538611321024892,
				0.10610826866553914,
				0.08249177585481285,
				0.08183725049104798
			],
			"llama-v3p1-8b-instruct": [
				0.028987626494887873,
				0.02743954906907115,
				0.020535027352053016,
				0.040368218256308694,
				0.036185365005201794,
				0.04042074667787635,
				0.048147350318655996,
				0.043855959000708135,
				0.027787138797985375,
				0.046253500870320124
			],
			"gpt-4o": [
				0.20870184910036524,
				0.21114460655524617,
				0.19738947733711393,
				0.18754705029682456,
				0.14096623083468027,
				0.16272443904169337,
				0.19036449682583817,
				0.1880806809246719,
				0.15412656195910565,
				0.14513899242032108
			],
			"llama-v3p1-405b-instruct": [
				0.2064124541676535,
				0.1878887565394446,
				0.19346005561156635,
				0.18744729176046576,
				0.16687119692950056,
				0.16600134313912904,
				0.20081948180668235,
				0.19689146182353046,
				0.15704216589398332,
				0.14508037502372992
			]
		},
		"san<en>": {
			"gpt-4o-mini": [
				0.14658882778369245,
				0.14609998417482098,
				0.14061725275199782,
				0.1449671016738362,
				0.10830508485535133,
				0.1333030764904852,
				0.14826339179340806,
				0.14487226933297795,
				0.12430079631279631,
				0.11933192650097756
			],
			"llama-v3p1-8b-instruct": [
				0.11145250123851971,
				0.11777055705955478,
				0.11333776088827198,
				0.12513840332996604,
				0.10594266056586316,
				0.123438193220891,
				0.13672155411353304,
				0.14255494793321127,
				0.10961575119259165,
				0.10619372374727591
			],
			"gpt-4o": [
				0.20000964889436568,
				0.20544882498203454,
				0.19478397844299777,
				0.19092464327982914,
				0.1422582764017916,
				0.17256272463446165,
				0.20143978260285147,
				0.18292585897236535,
				0.16020551064551164,
				0.15162652715182642
			],
			"llama-v3p1-405b-instruct": [
				0.20360736710604208,
				0.19679171249988478,
				0.19103955876111112,
				0.1999028279968223,
				0.17202532304883683,
				0.18476563894836429,
				0.218367053657817,
				0.2144843729564512,
				0.17896559421126082,
				0.16218449072946442
			]
		},
		"lat": {
			"gpt-4o-mini": [
				0.14575943316248163,
				0.17850356957049385,
				0.15941069000180863,
				0.1509335597801152,
				0.15346658681197253,
				0.1449873336593679,
				0.17771163399417023,
				0.16078329797229732,
				0.1514383864279448,
				0.15311849794197926
			],
			"llama-v3p1-8b-instruct": [
				0.12173609628241464,
				0.1486839206782168,
				0.14187076787673863,
				0.1117346260799469,
				0.12395677699290063,
				0.12154955349397292,
				0.1481023655163825,
				0.14312504845624024,
				0.11127668195410954,
				0.12482420496583074
			],
			"gpt-4o": [
				0.14698684241908475,
				0.20393015150966115,
				0.16812568597092237,
				0.15207944557923544,
				0.16574773339392265,
				0.14677685157842968,
				0.20337017448226405,
				0.1690387058511093,
				0.15265969942657856,
				0.16594931481154138
			],
			"llama-v3p1-405b-instruct": [
				0.17672115823577403,
				0.22902448517361576,
				0.20601476594580392,
				0.18486092391237918,
				0.1974230043042802,
				0.17636846561924957,
				0.2278362467730631,
				0.20821337418782623,
				0.18416351785015345,
				0.19809609252519988
			]
		},
		"lat<en>": {
			"gpt-4o-mini": [
				0.14228390406412428,
				0.17834450158625142,
				0.1592010854717884,
				0.14758869129274596,
				0.14610210801244317,
				0.14123344570139115,
				0.1777826107180086,
				0.16075102527938906,
				0.1479058706257311,
				0.14580352249630674
			],
			"llama-v3p1-8b-instruct": [
				0.1309756432653269,
				0.1694776315669624,
				0.14856487342454544,
				0.1321566541820451,
				0.1379011239792561,
				0.1306000935541673,
				0.16873944583473036,
				0.1495347167436081,
				0.13184491429096798,
				0.13841438222230237
			],
			"gpt-4o": [
				0.15630693491454736,
				0.20646433474106896,
				0.17258942937641256,
				0.1623949850428995,
				0.1634049513012501,
				0.15547060598932183,
				0.20575372390710825,
				0.17434870562433816,
				0.1622022483704429,
				0.16357093089797126
			],
			"llama-v3p1-405b-instruct": [
				0.1696888260259618,
				0.22240627410814526,
				0.20905892673907622,
				0.18305678126344774,
				0.18507673366092928,
				0.16908294686554348,
				0.22149647892162508,
				0.21110446055620172,
				0.18282735444995712,
				0.18523521613439498
			]
		},
		"grc": {
			"gpt-4o-mini": [
				0.18947098646182414,
				0.1935473555139632,
				0.17942000767893995,
				0.14571295859726144,
				0.1132731559777636,
				0.19020721082726877,
				0.20640599083208172,
				0.1718961104291164,
				0.1436590681907381,
				0.11282112976145887
			],
			"llama-v3p1-8b-instruct": [
				0.1404246401544144,
				0.12564461585775757,
				0.1216669097802979,
				0.17263007971799366,
				0.10844321983516864,
				0.13885346971005383,
				0.1303626924639498,
				0.11981392801178932,
				0.1727541316854725,
				0.108248203475499
			],
			"gpt-4o": [
				0.29631075833775206,
				0.3429458496410298,
				0.22418218035654836,
				0.19718593610822682,
				0.1361596582239229,
				0.307678929986386,
				0.35393753392988053,
				0.21944145491469913,
				0.19283983579495953,
				0.13893963916571017
			],
			"llama-v3p1-405b-instruct": [
				0.3695634138225357,
				0.30865604859748774,
				0.291564323871089,
				0.2639783274490053,
				0.17468364146268522,
				0.3841355711010391,
				0.315198470396255,
				0.2924952026402757,
				0.2602158063756337,
				0.179139509729202
			]
		},
		"grc<en>": {
			"gpt-4o-mini": [
				0.2211735624788439,
				0.19404671071037202,
				0.187933153473453,
				0.14546233047794288,
				0.10415275784215935,
				0.22115049726755057,
				0.20542877181618033,
				0.18130267184386445,
				0.14481086627549108,
				0.10282708654405374
			],
			"llama-v3p1-8b-instruct": [
				0.15648776128054848,
				0.1455083841394299,
				0.13853694089765645,
				0.18316346565289846,
				0.12591849901348184,
				0.15431171676632938,
				0.15193624537719555,
				0.13373330508648387,
				0.1829075700592032,
				0.12502347163043434
			],
			"gpt-4o": [
				0.3151844225759792,
				0.3082058436235335,
				0.24912165022019603,
				0.20852616668744395,
				0.13506952333266128,
				0.3293860799840395,
				0.3161495863950389,
				0.2414610269827078,
				0.20633896844734473,
				0.1378411764654715
			],
			"llama-v3p1-405b-instruct": [
				0.3439971761643119,
				0.30162278887019256,
				0.2745361964528168,
				0.2504914529511687,
				0.19025973985307193,
				0.3557256711916514,
				0.31583435039685714,
				0.2672105658287314,
				0.25013959233720057,
				0.1942472704845449
			]
		}
	},
	"(c) Question Answering san - Overall": {
		"closed": {
			"gpt-4o-mini": [
				0.039735099337748346,
				0.006622516556291391,
				0.006622516556291391,
				0.019867549668874173,
				0.16556291390728478,
				0.1456953642384106,
				0.046357615894039736,
				0.039735099337748346,
				0.0728476821192053,
				0.1056338028169014
			],
			"llama-v3p1-8b-instruct": [
				0.039735099337748346,
				0.013245033112582781,
				0.0,
				0.06622516556291391,
				0.16556291390728478,
				0.13245033112582782,
				0.052980132450331126,
				0.06622516556291391,
				0.12582781456953643,
				0.16901408450704225
			],
			"gpt-4o": [
				0.36423841059602646,
				0.2980132450331126,
				0.2781456953642384,
				0.3841059602649007,
				0.6158940397350994,
				0.5960264900662252,
				0.3576158940397351,
				0.2251655629139073,
				0.31125827814569534,
				0.44366197183098594
			],
			"llama-v3p1-405b-instruct": [
				0.3708609271523179,
				0.33112582781456956,
				0.32450331125827814,
				0.39072847682119205,
				0.5033112582781457,
				0.5695364238410596,
				0.2913907284768212,
				0.1456953642384106,
				0.26490066225165565,
				0.3028169014084507
			]
		},
		"+RAG-BM25": {
			"gpt-4o-mini": [
				0.013245033112582781,
				0.0,
				0.019867549668874173,
				0.0,
				0.11258278145695365,
				0.06622516556291391,
				0.026490066225165563,
				0.006622516556291391,
				0.013245033112582781,
				0.02112676056338028
			],
			"llama-v3p1-8b-instruct": [
				0.059602649006622516,
				0.013245033112582781,
				0.019867549668874173,
				0.06622516556291391,
				0.152317880794702,
				0.17218543046357615,
				0.07947019867549669,
				0.0728476821192053,
				0.06622516556291391,
				0.13380281690140844
			],
			"gpt-4o": [
				0.44370860927152317,
				0.33774834437086093,
				0.3708609271523179,
				0.45695364238410596,
				0.5562913907284768,
				0.5761589403973509,
				0.45695364238410596,
				0.5165562913907285,
				0.4768211920529801,
				0.5985915492957746
			],
			"llama-v3p1-405b-instruct": [
				0.31788079470198677,
				0.2582781456953642,
				0.31125827814569534,
				0.3443708609271523,
				0.4304635761589404,
				0.4503311258278146,
				0.271523178807947,
				0.2913907284768212,
				0.26490066225165565,
				0.323943661971831
			]
		},
		"closed<en>": {
			"gpt-4o-mini": [
				0.07947019867549669,
				0.10596026490066225,
				0.07947019867549669,
				0.09933774834437085,
				0.32450331125827814,
				0.23841059602649006,
				0.16556291390728478,
				0.17880794701986755,
				0.18543046357615894,
				0.31690140845070425
			],
			"llama-v3p1-8b-instruct": [
				0.052980132450331126,
				0.06622516556291391,
				0.033112582781456956,
				0.09271523178807947,
				0.2251655629139073,
				0.2119205298013245,
				0.059602649006622516,
				0.1390728476821192,
				0.15894039735099338,
				0.2605633802816901
			],
			"gpt-4o": [
				0.3443708609271523,
				0.2582781456953642,
				0.24503311258278146,
				0.36423841059602646,
				0.543046357615894,
				0.5231788079470199,
				0.271523178807947,
				0.2582781456953642,
				0.33774834437086093,
				0.4225352112676056
			],
			"llama-v3p1-405b-instruct": [
				0.39072847682119205,
				0.3509933774834437,
				0.33774834437086093,
				0.4304635761589404,
				0.5960264900662252,
				0.5827814569536424,
				0.2913907284768212,
				0.3576158940397351,
				0.36423841059602646,
				0.39436619718309857
			]
		},
		"+RAG-BM25<en>": {
			"gpt-4o-mini": [
				0.18543046357615894,
				0.11920529801324503,
				0.1456953642384106,
				0.12582781456953643,
				0.3509933774834437,
				0.31125827814569534,
				0.2847682119205298,
				0.26490066225165565,
				0.304635761589404,
				0.4507042253521127
			],
			"llama-v3p1-8b-instruct": [
				0.006622516556291391,
				0.006622516556291391,
				0.006622516556291391,
				0.019867549668874173,
				0.0728476821192053,
				0.11258278145695365,
				0.08609271523178808,
				0.12582781456953643,
				0.18543046357615894,
				0.2746478873239437
			],
			"gpt-4o": [
				0.423841059602649,
				0.31125827814569534,
				0.3841059602649007,
				0.423841059602649,
				0.5629139072847682,
				0.5761589403973509,
				0.4503311258278146,
				0.4304635761589404,
				0.4370860927152318,
				0.6338028169014085
			],
			"llama-v3p1-405b-instruct": [
				0.3708609271523179,
				0.31788079470198677,
				0.2781456953642384,
				0.37748344370860926,
				0.4900662251655629,
				0.5165562913907285,
				0.3576158940397351,
				0.4966887417218543,
				0.423841059602649,
				0.5633802816901409
			]
		}
	},
	"(d) Question Answering san - Answer in Context": {
		"closed": {
			"gpt-4o-mini": [
				0.04918032786885246,
				0.0,
				0.01639344262295082,
				0.18032786885245902,
				0.13114754098360656,
				0.09836065573770492,
				0.03278688524590164,
				0.08196721311475409,
				0.06557377049180328,
				0.13793103448275862
			],
			"llama-v3p1-8b-instruct": [
				0.06557377049180328,
				0.01639344262295082,
				0.03278688524590164,
				0.14754098360655737,
				0.11475409836065574,
				0.09836065573770492,
				0.06557377049180328,
				0.06557377049180328,
				0.21311475409836064,
				0.13793103448275862
			],
			"gpt-4o": [
				0.4262295081967213,
				0.4098360655737705,
				0.3442622950819672,
				0.639344262295082,
				0.7049180327868853,
				0.3770491803278688,
				0.21311475409836064,
				0.21311475409836064,
				0.29508196721311475,
				0.39655172413793105
			],
			"llama-v3p1-405b-instruct": [
				0.4098360655737705,
				0.36065573770491804,
				0.29508196721311475,
				0.6065573770491803,
				0.5901639344262295,
				0.26229508196721313,
				0.04918032786885246,
				0.21311475409836064,
				0.2786885245901639,
				0.3448275862068966
			]
		},
		"+RAG-BM25": {
			"gpt-4o-mini": [
				0.01639344262295082,
				0.04918032786885246,
				0.0,
				0.13114754098360656,
				0.08196721311475409,
				0.04918032786885246,
				0.0,
				0.03278688524590164,
				0.01639344262295082,
				0.034482758620689655
			],
			"llama-v3p1-8b-instruct": [
				0.13114754098360656,
				0.04918032786885246,
				0.06557377049180328,
				0.18032786885245902,
				0.14754098360655737,
				0.21311475409836064,
				0.04918032786885246,
				0.04918032786885246,
				0.13114754098360656,
				0.1206896551724138
			],
			"gpt-4o": [
				0.6721311475409836,
				0.6885245901639344,
				0.639344262295082,
				0.7049180327868853,
				0.6885245901639344,
				0.6721311475409836,
				0.5901639344262295,
				0.6721311475409836,
				0.6885245901639344,
				0.7068965517241379
			],
			"llama-v3p1-405b-instruct": [
				0.5737704918032787,
				0.47540983606557374,
				0.4426229508196721,
				0.5245901639344263,
				0.5901639344262295,
				0.4262295081967213,
				0.3442622950819672,
				0.2786885245901639,
				0.3770491803278688,
				0.3620689655172414
			]
		},
		"closed<en>": {
			"gpt-4o-mini": [
				0.11475409836065574,
				0.11475409836065574,
				0.11475409836065574,
				0.3114754098360656,
				0.2459016393442623,
				0.2459016393442623,
				0.14754098360655737,
				0.09836065573770492,
				0.29508196721311475,
				0.29310344827586204
			],
			"llama-v3p1-8b-instruct": [
				0.08196721311475409,
				0.04918032786885246,
				0.08196721311475409,
				0.2459016393442623,
				0.13114754098360656,
				0.09836065573770492,
				0.11475409836065574,
				0.08196721311475409,
				0.2459016393442623,
				0.1724137931034483
			],
			"gpt-4o": [
				0.39344262295081966,
				0.3114754098360656,
				0.36065573770491804,
				0.5409836065573771,
				0.6065573770491803,
				0.29508196721311475,
				0.26229508196721313,
				0.26229508196721313,
				0.36065573770491804,
				0.41379310344827586
			],
			"llama-v3p1-405b-instruct": [
				0.4262295081967213,
				0.39344262295081966,
				0.29508196721311475,
				0.6885245901639344,
				0.6229508196721312,
				0.19672131147540983,
				0.32786885245901637,
				0.26229508196721313,
				0.39344262295081966,
				0.43103448275862066
			]
		},
		"+RAG-BM25<en>": {
			"gpt-4o-mini": [
				0.32786885245901637,
				0.36065573770491804,
				0.26229508196721313,
				0.4426229508196721,
				0.45901639344262296,
				0.4918032786885246,
				0.26229508196721313,
				0.32786885245901637,
				0.4098360655737705,
				0.5
			],
			"llama-v3p1-8b-instruct": [
				0.01639344262295082,
				0.0,
				0.0,
				0.04918032786885246,
				0.13114754098360656,
				0.2459016393442623,
				0.09836065573770492,
				0.08196721311475409,
				0.29508196721311475,
				0.3103448275862069
			],
			"gpt-4o": [
				0.7049180327868853,
				0.6557377049180327,
				0.6229508196721312,
				0.6229508196721312,
				0.6557377049180327,
				0.6557377049180327,
				0.45901639344262296,
				0.5409836065573771,
				0.7213114754098361,
				0.7758620689655172
			],
			"llama-v3p1-405b-instruct": [
				0.639344262295082,
				0.5901639344262295,
				0.4426229508196721,
				0.639344262295082,
				0.639344262295082,
				0.5573770491803278,
				0.6065573770491803,
				0.5901639344262295,
				0.6557377049180327,
				0.7413793103448276
			]
		}
	},
	"(e) Question Answering san - Answer not in Context": {
		"closed": {
			"gpt-4o-mini": [
				0.03333333333333333,
				0.011111111111111112,
				0.011111111111111112,
				0.0,
				0.022222222222222223,
				0.25555555555555554,
				0.05555555555555555,
				0.03333333333333333,
				0.044444444444444446,
				0.08333333333333333
			],
			"llama-v3p1-8b-instruct": [
				0.03333333333333333,
				0.0,
				0.0,
				0.05555555555555555,
				0.08888888888888889,
				0.23333333333333334,
				0.03333333333333333,
				0.044444444444444446,
				0.1,
				0.15476190476190477
			],
			"gpt-4o": [
				0.28888888888888886,
				0.2222222222222222,
				0.34444444444444444,
				0.26666666666666666,
				0.4888888888888889,
				0.6555555555555556,
				0.43333333333333335,
				0.2777777777777778,
				0.28888888888888886,
				0.5119047619047619
			],
			"llama-v3p1-405b-instruct": [
				0.34444444444444444,
				0.32222222222222224,
				0.32222222222222224,
				0.3888888888888889,
				0.3888888888888889,
				0.5777777777777777,
				0.45555555555555555,
				0.24444444444444444,
				0.25555555555555554,
				0.25
			]
		},
		"+RAG-BM25": {
			"gpt-4o-mini": [
				0.0,
				0.011111111111111112,
				0.0,
				0.0,
				0.0,
				0.13333333333333333,
				0.022222222222222223,
				0.011111111111111112,
				0.0,
				0.011904761904761904
			],
			"llama-v3p1-8b-instruct": [
				0.011111111111111112,
				0.0,
				0.011111111111111112,
				0.011111111111111112,
				0.1,
				0.24444444444444444,
				0.044444444444444446,
				0.044444444444444446,
				0.06666666666666667,
				0.09523809523809523
			],
			"gpt-4o": [
				0.3111111111111111,
				0.17777777777777778,
				0.3,
				0.26666666666666666,
				0.4222222222222222,
				0.5777777777777777,
				0.3888888888888889,
				0.2777777777777778,
				0.3333333333333333,
				0.4166666666666667
			],
			"llama-v3p1-405b-instruct": [
				0.18888888888888888,
				0.2,
				0.2222222222222222,
				0.2222222222222222,
				0.34444444444444444,
				0.4444444444444444,
				0.26666666666666666,
				0.1111111111111111,
				0.32222222222222224,
				0.16666666666666666
			]
		},
		"closed<en>": {
			"gpt-4o-mini": [
				0.05555555555555555,
				0.05555555555555555,
				0.1111111111111111,
				0.06666666666666667,
				0.17777777777777778,
				0.4111111111111111,
				0.08888888888888889,
				0.16666666666666666,
				0.17777777777777778,
				0.32142857142857145
			],
			"llama-v3p1-8b-instruct": [
				0.044444444444444446,
				0.044444444444444446,
				0.03333333333333333,
				0.05555555555555555,
				0.14444444444444443,
				0.3111111111111111,
				0.1111111111111111,
				0.1,
				0.18888888888888888,
				0.2619047619047619
			],
			"gpt-4o": [
				0.3,
				0.2111111111111111,
				0.26666666666666666,
				0.24444444444444444,
				0.4888888888888889,
				0.6111111111111112,
				0.3333333333333333,
				0.2111111111111111,
				0.3,
				0.44047619047619047
			],
			"llama-v3p1-405b-instruct": [
				0.36666666666666664,
				0.3333333333333333,
				0.35555555555555557,
				0.3888888888888889,
				0.4777777777777778,
				0.6333333333333333,
				0.5,
				0.3,
				0.4222222222222222,
				0.35714285714285715
			]
		},
		"+RAG-BM25<en>": {
			"gpt-4o-mini": [
				0.08888888888888889,
				0.07777777777777778,
				0.08888888888888889,
				0.022222222222222223,
				0.1,
				0.43333333333333335,
				0.07777777777777778,
				0.14444444444444443,
				0.25555555555555554,
				0.36904761904761907
			],
			"llama-v3p1-8b-instruct": [
				0.0,
				0.011111111111111112,
				0.011111111111111112,
				0.0,
				0.03333333333333333,
				0.15555555555555556,
				0.03333333333333333,
				0.03333333333333333,
				0.15555555555555556,
				0.23809523809523808
			],
			"gpt-4o": [
				0.3111111111111111,
				0.14444444444444443,
				0.28888888888888886,
				0.25555555555555554,
				0.4111111111111111,
				0.6222222222222222,
				0.3888888888888889,
				0.28888888888888886,
				0.3,
				0.40476190476190477
			],
			"llama-v3p1-405b-instruct": [
				0.18888888888888888,
				0.25555555555555554,
				0.25555555555555554,
				0.16666666666666666,
				0.36666666666666664,
				0.5,
				0.32222222222222224,
				0.23333333333333334,
				0.25555555555555554,
				0.34523809523809523
			]
		}
	}
}