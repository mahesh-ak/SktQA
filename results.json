{
	"(a) Named Entity Recognition": {
		"san": {
			"gpt-4o-mini": [
				0.6597476597476598,
				0.7222222222222222,
				0.5940012368583797,
				0.6527777777777778,
				0.26206896551724135,
				0.18679653679653682,
				0.43205813794049086,
				0.28865578865578867,
				0.28775510204081634,
				0.2855699855699856
			],
			"llama-v3p1-8b-instruct": [
				0.4107142857142857,
				0.07142857142857142,
				0.09523809523809525,
				0.09292929292929294,
				0.19444444444444445,
				0.0,
				0.06222222222222222,
				0.025974025974025976,
				0.043478260869565216,
				0.2043650793650794
			],
			"gpt-4o": [
				0.4938453159041394,
				0.47521367521367525,
				0.6451923076923077,
				0.875,
				0.29895104895104896,
				0.3276353276353276,
				0.483982683982684,
				0.5427350427350428,
				0.30380116959064324,
				0.5286437246963562
			],
			"llama-v3p1-405b-instruct": [
				0.6054987212276215,
				0.4258953168044078,
				0.5013205282112845,
				0.7696969696969697,
				0.358974358974359,
				0.3621399176954732,
				0.34498834498834496,
				0.3724937343358396,
				0.3443010752688172,
				0.24924379915305503
			]
		},
		"lat": {
			"gpt-4o-mini": [
				0.46662093358359774,
				0.4086341714660299,
				0.3732503607503608,
				0.3805717282979282,
				0.37984496124031003,
				0.4283706631532718,
				0.33838974947408684,
				0.44296119162429326,
				0.3522177015940773,
				0.3303567071683014
			],
			"llama-v3p1-8b-instruct": [
				0.29410815774452137,
				0.24903486337326694,
				0.19779693486590041,
				0.14276832502252168,
				0.13419129060480342,
				0.11779560308972074,
				0.13025641025641024,
				0.19162363740677,
				0.2070656092285508,
				0.1679634214595369
			],
			"gpt-4o": [
				0.7056296450188196,
				0.5782770562770562,
				0.463785046728972,
				0.507539625186684,
				0.5015873015873016,
				0.47320128277683454,
				0.4019830613509605,
				0.5466448266448266,
				0.4316046018197837,
				0.41031321619556915
			],
			"llama-v3p1-405b-instruct": [
				0.6687014706269357,
				0.6145519077196097,
				0.5164983164983165,
				0.5096961604235482,
				0.41822172584423045,
				0.46989463552140803,
				0.5446748591909881,
				0.410595314850634,
				0.41288713278183425,
				0.4027465667915106
			]
		},
		"grc": {
			"gpt-4o-mini": [
				0.3132455298608468,
				0.1630981583353328,
				0.16455372136927332,
				0.1820349824100393,
				0.18857148654599384,
				0.21583966097241125,
				0.19477248138072722,
				0.20252968589468084,
				0.2956791473205238,
				0.22761007108833198
			],
			"llama-v3p1-8b-instruct": [
				0.13007407407407406,
				0.14030631402988794,
				0.10159769727643453,
				0.09508361681518293,
				0.13306748036122143,
				0.10348976860397312,
				0.10212714418526374,
				0.10259808708037593,
				0.08562062857479852,
				0.11777101163045862
			],
			"gpt-4o": [
				0.3394766623972782,
				0.3014860478275113,
				0.3180316295961507,
				0.4065969441060495,
				0.5945132429322751,
				0.3264305977122838,
				0.3409919100984621,
				0.31829643156052656,
				0.46967189514298324,
				0.3895161784361411
			],
			"llama-v3p1-405b-instruct": [
				0.5945613592291359,
				0.2984449166364711,
				0.2896166186489582,
				0.3296049068176674,
				0.528505311886018,
				0.3291020065077287,
				0.34750020944874305,
				0.42258129787382476,
				0.4179241125009329,
				0.41485210721254157
			]
		}
	},
	"(b) Machine Translation to English": {
		"san": {
			"gpt-4o-mini": [
				0.06269203190084,
				0.07298964835309736,
				0.07232927350178348,
				0.07868631860260283,
				0.07500842319758556,
				0.09548955416518026,
				0.10538611321024892,
				0.10610826866553914,
				0.08249177585481285,
				0.08183725049104798
			],
			"llama-v3p1-8b-instruct": [
				0.028987626494887873,
				0.02743954906907115,
				0.020535027352053016,
				0.040368218256308694,
				0.036185365005201794,
				0.04042074667787635,
				0.048147350318655996,
				0.043855959000708135,
				0.027787138797985375,
				0.046253500870320124
			],
			"gpt-4o": [
				0.20870184910036524,
				0.21114460655524617,
				0.19738947733711393,
				0.18754705029682456,
				0.14096623083468027,
				0.16272443904169337,
				0.19036449682583817,
				0.1880806809246719,
				0.15412656195910565,
				0.14513899242032108
			],
			"llama-v3p1-405b-instruct": [
				0.2064124541676535,
				0.1878887565394446,
				0.19346005561156635,
				0.18744729176046576,
				0.16687119692950056,
				0.16600134313912904,
				0.20081948180668235,
				0.19689146182353046,
				0.15704216589398332,
				0.14508037502372992
			]
		},
		"lat": {
			"gpt-4o-mini": [
				0.14228390406412428,
				0.17834450158625142,
				0.1592010854717884,
				0.14758869129274596,
				0.14610210801244317,
				0.14123344570139115,
				0.1777826107180086,
				0.16075102527938906,
				0.1479058706257311,
				0.14580352249630674
			],
			"llama-v3p1-8b-instruct": [
				0.1309756432653269,
				0.1694776315669624,
				0.14856487342454544,
				0.1321566541820451,
				0.1379011239792561,
				0.1306000935541673,
				0.16873944583473036,
				0.1495347167436081,
				0.13184491429096798,
				0.13841438222230237
			],
			"gpt-4o": [
				0.15630693491454736,
				0.20646433474106896,
				0.17258942937641256,
				0.1623949850428995,
				0.1634049513012501,
				0.15547060598932183,
				0.20575372390710825,
				0.17434870562433816,
				0.1622022483704429,
				0.16357093089797126
			],
			"llama-v3p1-405b-instruct": [
				0.1696888260259618,
				0.22240627410814526,
				0.20905892673907622,
				0.18305678126344774,
				0.18507673366092928,
				0.16908294686554348,
				0.22149647892162508,
				0.21110446055620172,
				0.18282735444995712,
				0.18523521613439498
			]
		},
		"grc": {
			"gpt-4o-mini": [
				0.2211735624788439,
				0.19404671071037202,
				0.187933153473453,
				0.14546233047794288,
				0.10415275784215935,
				0.22115049726755057,
				0.20542877181618033,
				0.18130267184386445,
				0.14481086627549108,
				0.10282708654405374
			],
			"llama-v3p1-8b-instruct": [
				0.15648776128054848,
				0.1455083841394299,
				0.13853694089765645,
				0.18316346565289846,
				0.12591849901348184,
				0.15431171676632938,
				0.15193624537719555,
				0.13373330508648387,
				0.1829075700592032,
				0.12502347163043434
			],
			"gpt-4o": [
				0.3151844225759792,
				0.3082058436235335,
				0.24912165022019603,
				0.20852616668744395,
				0.13506952333266128,
				0.3293860799840395,
				0.3161495863950389,
				0.2414610269827078,
				0.20633896844734473,
				0.1378411764654715
			],
			"llama-v3p1-405b-instruct": [
				0.3439971761643119,
				0.30162278887019256,
				0.2745361964528168,
				0.2504914529511687,
				0.19025973985307193,
				0.3557256711916514,
				0.31583435039685714,
				0.2672105658287314,
				0.25013959233720057,
				0.1942472704845449
			]
		}
	},
	"(c) Question Answering (san) - Overall": {
		"w/o context": {
			"gpt-4o-mini": [
				0.039735099337748346,
				0.006622516556291391,
				0.006622516556291391,
				0.019867549668874173,
				0.16556291390728478,
				0.1456953642384106,
				0.046357615894039736,
				0.039735099337748346,
				0.0728476821192053,
				0.1056338028169014
			],
			"llama-v3p1-8b-instruct": [
				0.039735099337748346,
				0.013245033112582781,
				0.0,
				0.06622516556291391,
				0.16556291390728478,
				0.13245033112582782,
				0.052980132450331126,
				0.06622516556291391,
				0.12582781456953643,
				0.16901408450704225
			],
			"gpt-4o": [
				0.36423841059602646,
				0.2913907284768212,
				0.2781456953642384,
				0.3841059602649007,
				0.6158940397350994,
				0.5960264900662252,
				0.3576158940397351,
				0.2251655629139073,
				0.31125827814569534,
				0.44366197183098594
			],
			"llama-v3p1-405b-instruct": [
				0.36423841059602646,
				0.32450331125827814,
				0.32450331125827814,
				0.3841059602649007,
				0.5033112582781457,
				0.5695364238410596,
				0.2913907284768212,
				0.1456953642384106,
				0.26490066225165565,
				0.3028169014084507
			]
		},
		"+ context (RAG-BM25)": {
			"gpt-4o-mini": [
				0.013245033112582781,
				0.0,
				0.019867549668874173,
				0.0,
				0.11258278145695365,
				0.06622516556291391,
				0.026490066225165563,
				0.006622516556291391,
				0.013245033112582781,
				0.02112676056338028
			],
			"llama-v3p1-8b-instruct": [
				0.059602649006622516,
				0.013245033112582781,
				0.019867549668874173,
				0.06622516556291391,
				0.152317880794702,
				0.17218543046357615,
				0.07947019867549669,
				0.0728476821192053,
				0.06622516556291391,
				0.13380281690140844
			],
			"gpt-4o": [
				0.4370860927152318,
				0.33774834437086093,
				0.3708609271523179,
				0.45695364238410596,
				0.5562913907284768,
				0.5761589403973509,
				0.45695364238410596,
				0.5165562913907285,
				0.4768211920529801,
				0.5985915492957746
			],
			"llama-v3p1-405b-instruct": [
				0.31125827814569534,
				0.2582781456953642,
				0.304635761589404,
				0.32450331125827814,
				0.4304635761589404,
				0.4503311258278146,
				0.271523178807947,
				0.2913907284768212,
				0.26490066225165565,
				0.323943661971831
			]
		}
	},
	"(d) Question Answering (san) - Answer in Context": {
		"w/o context": {
			"gpt-4o-mini": [
				0.04918032786885246,
				0.0,
				0.01639344262295082,
				0.18032786885245902,
				0.13114754098360656,
				0.09836065573770492,
				0.03278688524590164,
				0.08196721311475409,
				0.06557377049180328,
				0.13793103448275862
			],
			"llama-v3p1-8b-instruct": [
				0.06557377049180328,
				0.01639344262295082,
				0.03278688524590164,
				0.14754098360655737,
				0.11475409836065574,
				0.09836065573770492,
				0.06557377049180328,
				0.06557377049180328,
				0.21311475409836064,
				0.13793103448275862
			],
			"gpt-4o": [
				0.4262295081967213,
				0.4098360655737705,
				0.3442622950819672,
				0.639344262295082,
				0.7049180327868853,
				0.3770491803278688,
				0.21311475409836064,
				0.21311475409836064,
				0.29508196721311475,
				0.39655172413793105
			],
			"llama-v3p1-405b-instruct": [
				0.4098360655737705,
				0.36065573770491804,
				0.29508196721311475,
				0.6065573770491803,
				0.5901639344262295,
				0.26229508196721313,
				0.04918032786885246,
				0.21311475409836064,
				0.2786885245901639,
				0.3448275862068966
			]
		},
		"+ context (RAG-BM25)": {
			"gpt-4o-mini": [
				0.01639344262295082,
				0.04918032786885246,
				0.0,
				0.13114754098360656,
				0.08196721311475409,
				0.04918032786885246,
				0.0,
				0.03278688524590164,
				0.01639344262295082,
				0.034482758620689655
			],
			"llama-v3p1-8b-instruct": [
				0.13114754098360656,
				0.04918032786885246,
				0.06557377049180328,
				0.18032786885245902,
				0.14754098360655737,
				0.21311475409836064,
				0.04918032786885246,
				0.04918032786885246,
				0.13114754098360656,
				0.1206896551724138
			],
			"gpt-4o": [
				0.6721311475409836,
				0.6885245901639344,
				0.639344262295082,
				0.7049180327868853,
				0.6885245901639344,
				0.6721311475409836,
				0.5901639344262295,
				0.6721311475409836,
				0.6885245901639344,
				0.7068965517241379
			],
			"llama-v3p1-405b-instruct": [
				0.5573770491803278,
				0.47540983606557374,
				0.4262295081967213,
				0.5245901639344263,
				0.5901639344262295,
				0.4262295081967213,
				0.3442622950819672,
				0.2786885245901639,
				0.3770491803278688,
				0.3620689655172414
			]
		}
	},
	"(e) Question Answering (san) - Answer not in Context": {
		"w/o context": {
			"gpt-4o-mini": [
				0.03333333333333333,
				0.011111111111111112,
				0.011111111111111112,
				0.0,
				0.022222222222222223,
				0.25555555555555554,
				0.05555555555555555,
				0.03333333333333333,
				0.044444444444444446,
				0.08333333333333333
			],
			"llama-v3p1-8b-instruct": [
				0.03333333333333333,
				0.0,
				0.0,
				0.05555555555555555,
				0.08888888888888889,
				0.23333333333333334,
				0.03333333333333333,
				0.044444444444444446,
				0.1,
				0.15476190476190477
			],
			"gpt-4o": [
				0.28888888888888886,
				0.2111111111111111,
				0.34444444444444444,
				0.26666666666666666,
				0.4888888888888889,
				0.6555555555555556,
				0.43333333333333335,
				0.2777777777777778,
				0.28888888888888886,
				0.5119047619047619
			],
			"llama-v3p1-405b-instruct": [
				0.3333333333333333,
				0.3111111111111111,
				0.32222222222222224,
				0.37777777777777777,
				0.3888888888888889,
				0.5777777777777777,
				0.45555555555555555,
				0.24444444444444444,
				0.25555555555555554,
				0.25
			]
		},
		"+ context (RAG-BM25)": {
			"gpt-4o-mini": [
				0.0,
				0.011111111111111112,
				0.0,
				0.0,
				0.0,
				0.13333333333333333,
				0.022222222222222223,
				0.011111111111111112,
				0.0,
				0.011904761904761904
			],
			"llama-v3p1-8b-instruct": [
				0.011111111111111112,
				0.0,
				0.011111111111111112,
				0.011111111111111112,
				0.1,
				0.24444444444444444,
				0.044444444444444446,
				0.044444444444444446,
				0.06666666666666667,
				0.09523809523809523
			],
			"gpt-4o": [
				0.3,
				0.17777777777777778,
				0.3,
				0.26666666666666666,
				0.4222222222222222,
				0.5777777777777777,
				0.3888888888888889,
				0.2777777777777778,
				0.3333333333333333,
				0.4166666666666667
			],
			"llama-v3p1-405b-instruct": [
				0.18888888888888888,
				0.2,
				0.2222222222222222,
				0.2,
				0.3333333333333333,
				0.4444444444444444,
				0.26666666666666666,
				0.1111111111111111,
				0.32222222222222224,
				0.16666666666666666
			]
		}
	}
}